{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "\n",
    "import random\n",
    "from collections import *\n",
    "from math import *\n",
    "import pandas as pd\n",
    "# import modin.pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numexpr, bottleneck\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from plotnine import *\n",
    "import time\n",
    "\n",
    "random.seed(a=1, version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define main classes and functions for our simualations\n",
    "\n",
    "\n",
    "# 'Agent' sets up agents in our model and governs their beliefs formation and updating in the first and subsequent periods.\n",
    "class Agent:\n",
    "    \n",
    "    def __init__(self, id, type=0, start_actions=(random.randint(0,2),random.randint(0,2)), \n",
    "                 coop_threshold=0.5, punish_threshold_enforcer=0.5,punish_threshold_conformist=0.5, err_rate=0.05):\n",
    "        self.id = id\n",
    "        self.type = type\n",
    "        self.actions = start_actions\n",
    "        self.coop, self.punish  = self.actions \n",
    "        self.ct = coop_threshold\n",
    "        self.pt_enforcer = punish_threshold_enforcer\n",
    "        self.pt_conformist = punish_threshold_conformist\n",
    "        self.err_rate = err_rate\n",
    "        \n",
    "        \n",
    "    def initiate_belief(self, b0='random'):\n",
    "        if b0 == 'random':\n",
    "            self.belief_coop  = random.random()\n",
    "            self.belief_punish = random.random()\n",
    "        elif b0 == 'good':\n",
    "            self.belief_coop  = 1\n",
    "            self.belief_punish = 1\n",
    "        elif b0 == 'relatively good':\n",
    "            self.belief_coop  = 0.75\n",
    "            self.belief_punish = 0.75\n",
    "        elif b0 == 'relatively bad':\n",
    "            self.belief_coop  = 0.25\n",
    "            self.belief_punish = 0.25\n",
    "        elif b0 == 'bad':\n",
    "            self.belief_coop  = 0\n",
    "            self.belief_punish = 0\n",
    "            \n",
    "        \n",
    "   \n",
    "    def belief(self, sample):\n",
    "        num_agents = len(sample)\n",
    "        coops = [i.coop for i in sample]\n",
    "        self.belief_coop = sum(coops) / num_agents\n",
    "        punish = [i.punish for i in sample]\n",
    "        self.belief_punish = sum(punish) / num_agents\n",
    "            \n",
    "    def choose_coop(self):\n",
    "        # choose cooperation action\n",
    "        if random.random() < self.err_rate: # with prob. = err_rate, randomly pick a cooperation action\n",
    "            self.coop = random.randint(0,1)\n",
    "        else:\n",
    "            self.coop = self.belief_punish >= self.ct\n",
    "        \n",
    "    def choose_punish(self):\n",
    "        # choose punishment action\n",
    "        if random.random() < self.err_rate: # with prob. = err_rate, randomly pick a cooperation action\n",
    "            self.punish = random.randint(0,1)\n",
    "        else:\n",
    "            # the never-punish type\n",
    "            if self.type == 0: \n",
    "                self.punish = 0\n",
    "            # independent punishers\n",
    "            elif self.type == 1: \n",
    "                self.punish = 1\n",
    "            # norm-enforcers who punish iff enough others cooperate\n",
    "            elif self.type == 2: \n",
    "                self.punish = self.belief_coop > self.pt_enforcer\n",
    "            # conformists who punish iff enough others punish\n",
    "            elif self.type == 3: \n",
    "                self.punish = self.belief_punish > self.pt_conformist\n",
    "\n",
    "    def response(self):\n",
    "        self.choose_coop()\n",
    "        self.choose_punish()\n",
    "    \n",
    "    def update(self, sample, action='both'):\n",
    "        self.belief(sample)\n",
    "        if action=='both':\n",
    "            self.choose_coop()\n",
    "            self.choose_punish()\n",
    "        elif action=='coop':\n",
    "            self.choose_coop()\n",
    "        elif action=='punish':\n",
    "            self.choose_punish()\n",
    "            \n",
    "        \n",
    "# 'summary' provides summary statistics for agents generated by 'Agent'.\n",
    "# We will use the function to extract summary statistics for each period of the dynamic. \n",
    "def summary(agents, belief=False):\n",
    "    \n",
    "    num = len(agents)\n",
    "    cooperators = [i.coop for i in agents]\n",
    "    prop_coop = sum(cooperators) / num\n",
    "    \n",
    "    punishers = [i.punish for i in agents]\n",
    "    prop_punish = sum(punishers) / num\n",
    "    \n",
    "    if belief:\n",
    "        beliefs_coop = [agents[i].belief_coop for i in range(n)]\n",
    "        belief_coop = sum(beliefs_coop) / num\n",
    "\n",
    "        beliefs_punish = [agents[i].belief_punish for i in range(n)]\n",
    "        belief_punish = sum(beliefs_punish) / num\n",
    "    \n",
    "        summary = {\"belief_coop_prop\": belief_coop,\n",
    "                   \"belief_punish_prop\": belief_punish,\n",
    "                   \"cooperate_prop\": prop_coop,\n",
    "                   \"punish_prop\": prop_punish\n",
    "                  }\n",
    "    else:\n",
    "        summary = {\"cooperate_prop\": prop_coop,\n",
    "                   \"punish_prop\": prop_punish}\n",
    "\n",
    "    return summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# A simulation run includes: \n",
    "# 1) set up agents using 'Agent' in the first period; and repeat the following in subsequent periods, where\n",
    "# 2) update agents' beliefs and \n",
    "# 3) update actions. \n",
    "\n",
    "# The following function excute a simulation run\n",
    "# inputs of the function: n = population size, T = periods, update_rate = update probability of each agent in each period,\n",
    "#     e = mistake probability, sample_size = the number of agents that an agent samples from the population to form beliefs,\n",
    "#     start_by = whether intial states are determined by initial beliefs -- in this default case 'start_belief' expects an input specifying the initial beliefs,\n",
    "#     if start_by is not 'belief', then intial states are determined by inputs of 'start_coop' and 'start_punish'\n",
    "\n",
    "def run(n=100, T=100, types=(0,0,0), update_rate=0.5, e=0.1, sample_size=0.1, start_coop=0.5, start_punish=0.5,\n",
    "       start_belief='random', start_by='belief'):\n",
    "    \n",
    "    \n",
    "    # 0. population composition\n",
    "    \n",
    "    type1,type2,type3 = types\n",
    "    types = [1]*ceil(type1*n/100) + [2]*ceil(type2*n/100) + [3]*ceil(type3*n/100) \n",
    "    types = types + [0] * (n - len(types))\n",
    "\n",
    "    # 1. set up agents\n",
    "    if start_by == 'belief':\n",
    "        start_state = zip(range(n), types)\n",
    "        agents = [ Agent(id=i,type=t,err_rate=e) for i,t in start_state ]\n",
    "        [ agents[i].initiate_belief(b0=start_belief) for i in range(n)]\n",
    "        [ agents[i].response() for i in range(n) ]\n",
    "    else:\n",
    "        cooperation = [1] * round(start_coop*n) + [0] * (n - round(start_coop*n))\n",
    "        punishment = [1] * round(start_punish*n) + [0] * (n - round(start_punish*n))\n",
    "        start_state = zip(range(n), types, cooperation, punishment)\n",
    "        agents = [ Agent(id=i,type=t,err_rate=e,start_actions=(c, p) ) for i,t,c,p in start_state ]\n",
    "    \n",
    "    \n",
    "    # 2&3. update for T rounds \n",
    "\n",
    "    cooperate_prop = []\n",
    "    punish_prop = []\n",
    "    \n",
    "    if update_rate == 1:\n",
    "        \n",
    "        for t in range(T):\n",
    "            state = summary(agents)\n",
    "            cooperate_prop.append(state[\"cooperate_prop\"])\n",
    "            punish_prop.append(state[\"punish_prop\"])\n",
    "            \n",
    "            last_round_agents = agents\n",
    "            for i in range(n):\n",
    "                sample = random.choices(last_round_agents, k=ceil(sample_size*n) )\n",
    "                agents[i].update(sample)\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        for t in range(T):\n",
    "            state = summary(agents)\n",
    "            cooperate_prop.append(state[\"cooperate_prop\"])\n",
    "            punish_prop.append(state[\"punish_prop\"])\n",
    "\n",
    "            last_round_agents = agents\n",
    "            for i in range(n):\n",
    "                if random.random() <= update_rate:\n",
    "                    sample = random.choices(last_round_agents, k=ceil(sample_size*n) )\n",
    "                    agents[i].update(sample)\n",
    "                \n",
    "    data = {\"period\": range(0, T),\n",
    "            \"fc_cooperate\": cooperate_prop, # proportion of cooperators\n",
    "            \"fc_punish\": punish_prop} # proportion of punishers\n",
    "    \n",
    "    \n",
    "    return pd.DataFrame.from_dict(data) # store in a pandas dataframe   \n",
    "\n",
    "\n",
    "\n",
    "# the following function generates a list of population compositions in the format of tuples (a,b,c) \n",
    "# where a is the percentage (0-100) of independent punishers, b norm enforcers, and c conformist punishers.\n",
    "# the input 't1_list' expects a list of percentages (0-100) of independent punishers contained in the output.\n",
    "# the default input of 't1_list' is [0, 10, 20, ..., 50]. \n",
    "\n",
    "def gen_type_list(t1_list=range(0,51,10), step=10):\n",
    "    \n",
    "    types_list0 = []\n",
    "    types_list1 = []\n",
    "    for a in t1_list:\n",
    "        for b in range(0,101-a,step):\n",
    "            for c in range(0,101-a-b,step):\n",
    "                types_list0.append( (a,b,c) )\n",
    "        for c in range(0,101-a,10):\n",
    "            for b in range(0,101-a-c,step):\n",
    "                types_list1.append( (a,b,c) )\n",
    "    types_list = list(set(types_list0).union(set(types_list1)))\n",
    "    types_list.sort()\n",
    "    return types_list\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-26 16:57:57.360769\n",
      "2020-01-26 16:57:58.923518 (30, 0, 0) n30T50_STARTrelatively good_E0.05S0.1U0.5IP30NE0CP0G5trial0_50.h5 done Time used: 0 days 00:00:01.572456\n",
      "2020-01-26 16:57:58.939296 (30, 25, 25) n30T50_STARTrelatively good_E0.05S0.1U0.5IP30NE25CP25G5trial0_50.h5 done Time used: 0 days 00:00:01.587509\n",
      "2020-01-26 16:57:58.939281 (30, 50, 0) n30T50_STARTrelatively good_E0.05S0.1U0.5IP30NE50CP0G5trial0_50.h5 done Time used: 0 days 00:00:01.587766\n",
      "2020-01-26 16:57:58.934867 (30, 0, 50) n30T50_STARTrelatively good_E0.05S0.1U0.5IP30NE0CP50G5trial0_50.h5 done Time used: 0 days 00:00:01.577762\n",
      "2020-01-26 16:58:00.077149 (30, 0, 0) n30T50_STARTrelatively good_E0.05S0.1U0.5IP30NE0CP0G5trial50_100.h5 done Time used: 0 days 00:00:02.716941\n",
      "2020-01-26 16:58:00.100281 (30, 0, 50) n30T50_STARTrelatively good_E0.05S0.1U0.5IP30NE0CP50G5trial50_100.h5 done Time used: 0 days 00:00:02.740101\n",
      "2020-01-26 16:58:00.102111 (30, 25, 25) n30T50_STARTrelatively good_E0.05S0.1U0.5IP30NE25CP25G5trial50_100.h5 done Time used: 0 days 00:00:02.748604\n",
      "2020-01-26 16:58:00.102895 (30, 50, 0) n30T50_STARTrelatively good_E0.05S0.1U0.5IP30NE50CP0G5trial50_100.h5 done Time used: 0 days 00:00:02.751852\n"
     ]
    }
   ],
   "source": [
    "# The following block produces data for 'Starting High' in Fig. 3 in the paper.\n",
    "# For 'Starting Low' in Fig. 3, change 'initial_belief' to 'relatively bad'\n",
    "# For Fig. 4 and Fig. S8, raise T to 100,000; also, change population compositions in 'types_list' accordingly.\n",
    "# For Fig. S9, set types_list = gen_type_list(). \n",
    "\n",
    "#set parameters \n",
    "n = 100\n",
    "T = 10000\n",
    "\n",
    "err_rate = 0.05\n",
    "sample_size = 0.1\n",
    "update_rate = 0.5\n",
    "\n",
    "# set initial beliefs to b_c = b_p = 0.75\n",
    "# see how 'Agent' is defined\n",
    "initial_belief = 'relatively good'\n",
    "\n",
    "# fix independent punishers at 30%; vary % of norm enforcers and conformist punishers\n",
    "types_list = [(30, 0, 0), (30, 50, 0), (30, 0, 50), (30, 25, 25)]\n",
    "\n",
    "\n",
    "# for large T, the data size will be large; hence instead of saving data every period, the input 'gap' specifies saving the summary statistics every xxx periods.\n",
    "gap=5\n",
    "\n",
    "\n",
    "# the following function produces multiple runs (trials) for a given population composition in 'types_list'\n",
    "\n",
    "def runover(types, n=n, T=T, gap=gap,  e=err_rate, initial_belief=initial_belief):\n",
    "    type1,type2,type3 = types\n",
    "    \n",
    "    # for large T, the data size will quickly be large; so we save the data for every 50 runs (trials)\n",
    "    # in total, the following loop runs for 100 trials\n",
    "    # for 500 trials in Fig. 4 and S8, change to zip(range(0,500,100),range(50,501,100))\n",
    "    for a,b in zip(range(0,100,50),range(50,101,50) ) : \n",
    "        df_list0 = []\n",
    "        for i in range(a, b):\n",
    "            df_sub = run(n=n, T=T, types=(type1,type2,type3), e=e, update_rate=update_rate, start_belief=initial_belief,\n",
    "                             sample_size=sample_size)\n",
    "            select = ((df_sub['period'] % gap) == 0) | (df_sub['period'] < 1000) \n",
    "            df_sub = df_sub.loc[select]\n",
    "            df_sub[\"trial\"] = i # index the trial\n",
    "            df_sub[\"type1\"] = type1 # independent punishers\n",
    "            df_sub[\"type2\"] = type2 # norm enforcers\n",
    "            df_sub[\"type3\"] = type3 # conformist punishers\n",
    "            df_sub[\"start_belief\"] = initial_belief # record the category of intial beliefs \n",
    "            df_list0.append(df_sub)\n",
    "        df = pd.concat(df_list0)\n",
    "        file_name = f'n{n}T{T}_START{initial_belief}_E{err_rate}S{sample_size}U{update_rate}IP{type1}NE{type2}CP{type3}G{gap}trial{a}_{b}.h5'\n",
    "        try:\n",
    "            HDdata = pd.HDFStore(file_name) # the HD format saves and reads data fast. \n",
    "            HDdata['df'] = df\n",
    "            HDdata.close()\n",
    "        except:\n",
    "            HDdata.close()\n",
    "            HDdata = pd.HDFStore(file_name)\n",
    "            HDdata['df'] = df\n",
    "            HDdata.close()\n",
    "        print(pd.to_datetime('today'), (type1,type2,type3),file_name, 'done','Time used:', pd.to_datetime('today') - start_time)\n",
    "    \n",
    "    \n",
    "\n",
    "# finally, we use parallel processing to run over the population compositions in 'types_list'\n",
    "\n",
    "# show the starting time\n",
    "start_time = pd.to_datetime('today')\n",
    "print(start_time)\n",
    "\n",
    "pool = multiprocessing.Pool(processes=4)\n",
    "try:\n",
    "    pool.map(runover, types_list)\n",
    "except KeyboardInterrupt:\n",
    "    pool.terminate()\n",
    "    pool.join()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The remaining code process the simulation data to generate summary statistics for plotting Fig. 4, Fig. S8, and Fig. S9 in R\n",
    "\n",
    "\n",
    "# the following code transform the data from HD format to csv in order to process and plot Fig.3 in R\n",
    "n = 100\n",
    "T = 10000\n",
    "err_rate = 0.05\n",
    "sample_size = 0.1\n",
    "update_rate = 0.5\n",
    "gap = 5\n",
    "types_list = [(30, 0, 0), (30, 50, 0), (30, 0, 50), (30, 25, 25)]\n",
    "initial_beliefs = ['relatively good', 'relatively bad']\n",
    "allruns = zip(range(0,100,50),range(50,101,50) )\n",
    "df_list=[]\n",
    "for a,b in allruns:\n",
    "    for t1, t2, t3 in types_list:\n",
    "        for initial_belief in initial_beliefs:\n",
    "            file_name = f'n{n}T{T}_START{initial_belief}_E{err_rate}S{sample_size}U{update_rate}IP{t1}NE{t2}CP{t3}G{gap}trial{a}_{b}.h5'\n",
    "            HDdata = pd.HDFStore(file_name)\n",
    "            df = HDdata['df']\n",
    "            HDdata.close()\n",
    "            df_list.append(df.loc[df['period'] <= 10000])\n",
    "df = pd.concat(df_list)\n",
    "df.to_csv(f\"n{n}T10000_startbybelief_E{err_rate}S{sample_size}U{update_rate}IP30_NExCP50_0to100.csv\",index=False)\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot Fig. 4 and S8 in R, we define a function to generate cumulative density function (CDF) data\n",
    "# 'df' is the input data, in the form of pandas dataframe\n",
    "# the input 'cut' is the cutoff above (below) which we say a cooperation (defection) norm is established.\n",
    "# 'type_list' is the list of population compositions in the input data. \n",
    "# 'mode' specifies whether the function deals with the emergence of cooperation ('badtogood') or the breakdown of cooperation ('goodtobad').\n",
    "def CDFdata(df, cut=0.75, type_list=gen_type_list(), mode='goodtobad'):\n",
    "    \n",
    "    col = ['type1', 'type2', 'type3', 'trial', 'period', 'fc_cooperate', 'fc_punish']\n",
    "    trials = df['trial'].astype('category').cat.categories\n",
    "    append_list = []\n",
    "    \n",
    "    for t1,t2,t3 in type_list:\n",
    "        for i in trials: \n",
    "            append_list = append_list + [[t1, t2, t3, i, 999999999, 1, 1]] + [[t1, t2, t3, i, 999999998, 0, 0]]\n",
    "    add_df = pd.DataFrame(append_list, columns=col)\n",
    "    df2 = df.append(add_df)\n",
    "    \n",
    "    \n",
    "    if mode == 'goodtobad':\n",
    "        df_C = df2.loc[df2['fc_cooperate'] <= cut]\n",
    "    elif mode == 'badtogood':\n",
    "        select = (df2['fc_cooperate'] >= cut)\n",
    "        df_C = df2.loc[select]\n",
    "        \n",
    "    result = df_C.groupby(['type1', 'type2', 'type3','trial'], as_index=False)[\"period\"].min()\n",
    "    \n",
    "    result['types'] = ('NE=' + result['type2'].astype(str) + '%, CP=' + result['type3'].astype(str) + '%')\n",
    "    result['log_period'] = np.log10(result['period'])\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# The following code read the simulation data for Fig. 4\n",
    "n=100\n",
    "T=100000\n",
    "allruns = zip(range(0,500,100),range(50,501,100))\n",
    "\n",
    "types_list = [(30, 0, 50), (30, 25, 25), (30, 50, 0)]\n",
    "initial_belief = 'relatively bad'\n",
    "cdf_badlist=[]\n",
    "for a,b in allruns:\n",
    "    for t1, t2, t3 in types_list:\n",
    "        file_name = f'n{n}T{T}_START{initial_belief}_E0.05S0.1U0.5IP{t1}NE{t2}CP{t3}G5trial{a}_{b}.h5.h5'\n",
    "        HDdata = pd.HDFStore(file_name)\n",
    "        df = HDdata['df']\n",
    "        HDdata.close()\n",
    "        dfbad = df.loc[df['start_belief'] == 'bad']\n",
    "        cdfbad = CDFdata(dfbad, type_list=[(t1, t2, t3)],  mode='badtogood', cut=0.75)\n",
    "        cdf_badlist.append(cdfbad)\n",
    "  \n",
    "types_list = [(30, 0, 30), (30, 15, 15), (30, 30, 0)]\n",
    "initial_belief = 'relatively good'\n",
    "cdf_goodlist=[]\n",
    "for a,b in allruns:\n",
    "    for t1, t2, t3 in types_list:\n",
    "        file_name = f'n{n}T{T}_START{initial_belief}_E0.05S0.1U0.5IP{t1}NE{t2}CP{t3}G5trial{a}_{b}.h5.h5'\n",
    "        HDdata = pd.HDFStore(file_name)\n",
    "        df = HDdata['df']\n",
    "        HDdata.close()\n",
    "        dfgood = df.loc[df['start_belief'] == 'good']\n",
    "        cdfgood = CDFdata(dfgood, type_list=[(t1, t2, t3)],  mode='goodtobad', cut=0.25)\n",
    "        cdf_goodlist.append(cdfgood)\n",
    "        \n",
    "cdfgood = pd.concat(cdf_goodlist)\n",
    "print(Counter(cdfgood['types']))\n",
    "cdfbad = pd.concat(cdf_badlist)\n",
    "print(Counter(cdfbad['types']))\n",
    "\n",
    "        \n",
    "# export the cdf data\n",
    "cdfgood.to_csv(f\"cdf_n{n}T{T}_STARTrelatively good_E0.05S0.1U0.5IP30_NExCP30_0to500_cut25.csv\",index=False)\n",
    "cdfbad.to_csv(f\"cdf_n{n}T{T}_STARTrelatively bad_E0.05S0.1U0.5IP30_NExCP50_0to500_cut75.csv\",index=False)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
